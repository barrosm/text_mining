{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "navigate_num": "#000000",
        "navigate_text": "#333333",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700",
        "sidebar_border": "#EEEEEE",
        "wrapper_background": "#FFFFFF"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "120px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 4,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false,
      "widenNotebook": false
    },
    "colab": {
      "name": "aula_20191123_machine learning com nlp.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DgK_8T790VSR",
        "H5dJrtJu0VSi",
        "7EMyKf3Y0VS5",
        "2DmODOI00VTI"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barrosm/text_mining/blob/master/aula_20191123_machine_learning_com_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5iX3PRf0VRu",
        "colab_type": "text"
      },
      "source": [
        "# Aprendizado de máquina e exercícios de NLP #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AJ4eh0x0XYI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6b6819b3-fd05-40fd-b094-b3d5c5c7f2ba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23wX_0GW0XN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "workdir_path = '/content/drive/My Drive/aula_20191123_leonardo/' #MODIFICAR!!! #Caminho para o seu workspace\n",
        "os.chdir(workdir_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qZ7QVR10VRx",
        "colab_type": "text"
      },
      "source": [
        "## Exercicio ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_EMnE710VRy",
        "colab_type": "text"
      },
      "source": [
        "Usaremos o conjunto de dados de revisão do Kaggle  para este exercício. O produto que focaremos neste momento é uma xícara de cappuccino. O objetivo desta semana é não apenas pré-processar os dados, mas classificar as revisões como positivas ou negativas com base no texto da revisão.\n",
        "\n",
        "O código a seguir ajudará você a carregar os dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGoaNY8R0VRz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b31b52df-05b7-434d-bf99-715d1badb49d"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzwYFJ8A0VR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-j4bWlPI0VR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5db83e75-c652-4d40-a5bd-bdf63e9b7785"
      },
      "source": [
        "data = pd.read_csv('coffee.csv')\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A2XP9IN4JOMROD</td>\n",
              "      <td>1</td>\n",
              "      <td>I wanted to love this. I was even prepared for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A2TS09JCXNV1VD</td>\n",
              "      <td>5</td>\n",
              "      <td>Grove Square Cappuccino Cups were excellent. T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AJ3L5J7GN09SV</td>\n",
              "      <td>2</td>\n",
              "      <td>I bought the Grove Square hazelnut cappuccino ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A3CZD34ZTUJME7</td>\n",
              "      <td>1</td>\n",
              "      <td>I love my Keurig, and I love most of the Keuri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AWKN396SHAQGP</td>\n",
              "      <td>1</td>\n",
              "      <td>It's a powdered drink. No filter in k-cup.&lt;br ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          user_id  stars                                            reviews\n",
              "0  A2XP9IN4JOMROD      1  I wanted to love this. I was even prepared for...\n",
              "1  A2TS09JCXNV1VD      5  Grove Square Cappuccino Cups were excellent. T...\n",
              "2   AJ3L5J7GN09SV      2  I bought the Grove Square hazelnut cappuccino ...\n",
              "3  A3CZD34ZTUJME7      1  I love my Keurig, and I love most of the Keuri...\n",
              "4   AWKN396SHAQGP      1  It's a powdered drink. No filter in k-cup.<br ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDY1UcBo0VR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymJb3xJZ0VSA",
        "colab_type": "text"
      },
      "source": [
        "## Desafio 1 ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "178gGImL0VSB",
        "colab_type": "text"
      },
      "source": [
        "* Determine quantas revisões existem no total.\n",
        "* Determine o percentual de 1, 2, 3, 4 e 5 estrelas.\n",
        "* Crie um novo conjunto de dados para modelagem com as seguintes colunas:\n",
        "      - Coluna 1: 'positivo' se revisão = 4 ou 5 e 'negativo' se revisão = 1 ou 2\n",
        "      - Coluna 2: texto de revisão\n",
        "* Veja o número de análises positivas e negativas no conjunto de dados recém-criado.\n",
        "\n",
        "Ponto de verificação: o conjunto de dados resultante deve ter 514 revisões.\n",
        "\n",
        "Use o código de pré-processamento abaixo para limpar os dados das revisões antes de passar para a modelagem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08fJ2Y1k0VSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Essa é com voces turma :)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAPa3JV0gm89",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54a31c6b-7491-42df-cc8e-90192dc5f6e0"
      },
      "source": [
        "# Número de revisões\n",
        "data.shape[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "542"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "adQJJaI30VSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Enquanto a maioria dos revisores deixa uma avaliação de 5 estrelas, também há uma boa parte deixando avaliações de 1 estrela\n",
        "data.stars.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1-bP3K90VSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Remover comentários de 3 estrelas\n",
        "data = data[data.stars!=3]\n",
        "\n",
        "# Defina 4/5 estrelas como positivas, o resto como negativo\n",
        "data['sentiment'] = np.where(data['stars'] >= 4, 'positive', 'negative')\n",
        "\n",
        "# Incluir apenas as colunas de opinião e comentários\n",
        "data = data[['sentiment', 'reviews']]\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSm9dyuo0VSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the length of the new dataset\n",
        "len(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2nMG_av0VSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verifique o comprimento do novo conjunto de dados\n",
        "data.sentiment.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5JqV60I0VSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Etapas de pré-processamento de texto - remova números, letras maiúsculas e pontuação\n",
        "import re\n",
        "import string\n",
        "\n",
        "alphanumeric = lambda x: re.sub(r\"\"\"\\w*\\d\\w*\"\"\", ' ', x)\n",
        "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
        "\n",
        "data['reviews'] = data.reviews.map(alphanumeric).map(punc_lower)\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgK_8T790VSR",
        "colab_type": "text"
      },
      "source": [
        "## Desafio 2 ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA1K63k70VSS",
        "colab_type": "text"
      },
      "source": [
        "Prepare os dados para modelagem:\n",
        "* Divida os dados em conjuntos de treinamento e teste. Você deve ter quatro conjuntos de dados - X_train, X_test, y_train, y_test\n",
        "\n",
        "Crie recursos numéricos com o Count Vectorizer. Crie duas matrizes de termo do documento:\n",
        "* Matriz 1: os termos devem ser unigramas (palavras únicas) e os valores devem ser contados por palavras (dica: esse é o padrão do vetor de contagem)\n",
        "* Matriz 2: os termos devem ser unigramas e bigrams e os valores devem ser valores binários\n",
        "\n",
        "Recomendação: Utilize a função de palavras de parada do Count Vectorizer para remover palavras de parada do texto das revisões."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpDecpZZ0VSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Divida os dados em conjuntos de dados X e y\n",
        "X = data.reviews\n",
        "y = data.sentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGRdLzPZ0VSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Divida os dados em conjuntos de treinamento e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnk12CjZ0VSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Número de revisões no conjunto de treinamento\n",
        "X_train.shape, y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwxnvpsF0VSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Número de revisões no conjunto de testes\n",
        "X_test.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aoGuB-00VSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A primeira matriz de termo de documento possui valores padrão de vetor de contagem - contagem de unigramas\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv1 = CountVectorizer(stop_words='english')\n",
        "\n",
        "X_train_cv1 = cv1.fit_transform(X_train)\n",
        "X_test_cv1  = cv1.transform(X_test)\n",
        "\n",
        "print(X_train_cv1.toarray().shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqdMWc8P0VSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A segunda matriz de termos de documento possui unigramas e bigrams e indicadores em vez de contagens\n",
        "cv2 = CountVectorizer(ngram_range=(1,2), binary=True, stop_words='english')\n",
        "\n",
        "X_train_cv2 = cv2.fit_transform(X_train)\n",
        "X_test_cv2  = cv2.transform(X_test)\n",
        "\n",
        "print(X_train_cv2.toarray().shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5dJrtJu0VSi",
        "colab_type": "text"
      },
      "source": [
        "## Desafio 3 ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AN_5G8Ha0VSi",
        "colab_type": "text"
      },
      "source": [
        "Use a regressão logística para classificar as críticas como positivas ou negativas. Faça isso para ambas as matrizes.\n",
        "* Ajuste um modelo de regressão logística nos dados de treinamento\n",
        "* Aplique o modelo nos dados de teste e calcule as seguintes métricas de erro: exatidão, precisão, recall, pontuação F1\n",
        "* Opcional: visualize a matriz de confusão para os dois modelos\n",
        "* Compare as métricas de erro das duas matrizes\n",
        "\n",
        "Recomendação: Crie uma função para calcular as métricas de erro, pois você fará isso várias vezes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz5vfhIu0VSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Crie um modelo de regressão logística para usar\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrNwpLvX0VSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Treine o primeiro modelo\n",
        "lr.fit(X_train_cv1, y_train)\n",
        "y_pred_cv1 = lr.predict(X_test_cv1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvNxUSB_0VSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Treine o segundo modelo\n",
        "lr.fit(X_train_cv2, y_train)\n",
        "y_pred_cv2 = lr.predict(X_test_cv2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaLCNlPU0VSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Crie uma função para calcular as métricas de erro, pois faremos isso várias vezes\n",
        "from __future__ import division\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def conf_matrix(actual, predicted):\n",
        "    cm = confusion_matrix(actual, predicted)\n",
        "    sns.heatmap(cm, xticklabels=['predicted_negative', 'predicted_positive'], \n",
        "                yticklabels=['actual_negative', 'actual_positive'], annot=True,\n",
        "                fmt='d', annot_kws={'fontsize':20}, cmap=\"YlGnBu\");\n",
        "\n",
        "    true_neg, false_pos = cm[0]\n",
        "    false_neg, true_pos = cm[1]\n",
        "    \n",
        "    a = true_pos + true_neg\n",
        "    b = true_pos + true_neg + false_pos + false_neg\n",
        "    print (a/b)\n",
        "    \n",
        "    accuracy = round(float((true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg)),3)\n",
        "    precision = round(float((true_pos) / (true_pos + false_pos)),3)\n",
        "    recall = round(float((true_pos) / (true_pos + false_neg)),3)\n",
        "    f1 = round(float(2 * (precision * recall) / (precision + recall)),3)\n",
        "\n",
        "    cm_results = [accuracy, precision, recall, f1]\n",
        "    return cm_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hBNVh4b40VSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To mapa de calor para o primeiro modelo de regressão logística\n",
        "cm1 = conf_matrix(y_test, y_pred_cv1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuCx-AA_0VSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# O mapa de calor para o segundo modelo de regressão logística\n",
        "cm2 = conf_matrix(y_test, y_pred_cv2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_mZYZoD0VS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile todas as métricas de erro em um quadro de dados para comparação\n",
        "results = pd.DataFrame(list(zip(cm1, cm2)))\n",
        "results = results.set_index([['Accuracy', 'Precision', 'Recall', 'F1 Score']])\n",
        "results.columns = ['LogReg1', 'LogReg2']\n",
        "results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFRFpnRN0VS5",
        "colab_type": "text"
      },
      "source": [
        "Comparando os dois modelos, o primeiro modelo tem melhor precisão, enquanto o segundo modelo tem melhor precisão e recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EMyKf3Y0VS5",
        "colab_type": "text"
      },
      "source": [
        "## Desafio 4 ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soXtNQy90VS6",
        "colab_type": "text"
      },
      "source": [
        "tentamos usar outra técnica de aprendizado de máquina para classificar essas análises como positivas ou negativas. Siga exatamente o mesmo exercício na etapa anterior, mas desta vez use Naive Bayes em vez de Regressão logística.\n",
        "\n",
        "Para dados de contagem, use[Multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB). Para dados binários, use [Bernoulli Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB).\n",
        "\n",
        "Compare os resultados dos modelos Regressão Logística e Naive Bayes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "xg3FOBbr0VS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ajuste o primeiro modelo Naive Bayes\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(X_train_cv1, y_train)\n",
        "\n",
        "y_pred_cv1_nb = mnb.predict(X_test_cv1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "XZiTMqxw0VS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ajuste o segundo modelo Naive Bayes\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "bnb = BernoulliNB()\n",
        "bnb.fit(X_train_cv2, y_train)\n",
        "\n",
        "y_pred_cv2_nb = bnb.predict(X_test_cv2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ByyxPlto0VS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Aqui está o mapa de calor para o primeiro modelo Naive Bayes\n",
        "cm3 = conf_matrix(y_test, y_pred_cv1_nb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XQtGk-E0VTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Aqui está o mapa de calor para o segundo modelo Naive Bayes\n",
        "cm4 = conf_matrix(y_test, y_pred_cv2_nb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GodBFnXL0VTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile todas as métricas de erro em um quadro de dados para comparação\n",
        "results_nb = pd.DataFrame(list(zip(cm3, cm4)))\n",
        "results_nb = results_nb.set_index([['Accuracy', 'Precision', 'Recall', 'F1 Score']])\n",
        "results_nb.columns = ['NB1', 'NB2']\n",
        "results_nb\n",
        "\n",
        "results = pd.concat([results, results_nb], axis=1)\n",
        "results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_d9eTqB0VTH",
        "colab_type": "text"
      },
      "source": [
        "O primeiro modelo Naive Bayes supera os dois modelos de regressão logística."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DmODOI00VTI",
        "colab_type": "text"
      },
      "source": [
        "## Desafio 5 ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZiRx18b0VTJ",
        "colab_type": "text"
      },
      "source": [
        "Até o momento, usamos o Count Vectorizer para criar matrizes de termos de documentos para inserir nos modelos. Para pelo menos um dos quatro modelos que você criou até agora, use o TF-IDF Vectorizer em vez do Count Vectorizer e verifique se ele melhora os resultados.\n",
        "\n",
        "De todos os modelos que você criou, qual modelo você acha que classifica melhor as críticas positivas e negativas para a xícara de cappuccino?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNTJ6tDc0VTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Crie versões TF-IDF dos vetorizadores de contagem criados anteriormente no exercício\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf1 = TfidfVectorizer(stop_words='english')\n",
        "X_train_tfidf1 = tfidf1.fit_transform(X_train)\n",
        "X_test_tfidf1  = tfidf1.transform(X_test)\n",
        "\n",
        "tfidf2 = TfidfVectorizer(ngram_range=(1,2), binary=True, stop_words='english')\n",
        "X_train_tfidf2 = tfidf2.fit_transform(X_train)\n",
        "X_test_tfidf2  = tfidf2.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNATL3AW0VTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ajuste a primeira regressão logística nos dados do TF-IDF\n",
        "lr.fit(X_train_tfidf1, y_train)\n",
        "y_pred_tfidf1_lr = lr.predict(X_test_tfidf1)\n",
        "cm5 = conf_matrix(y_test, y_pred_tfidf1_lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-naJTQ7q0VTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ajuste a segunda regressão logística nos dados do TF-IDF\n",
        "lr.fit(X_train_tfidf2, y_train)\n",
        "y_pred_tfidf2_lr = lr.predict(X_test_tfidf2)\n",
        "cm6 = conf_matrix(y_test, y_pred_tfidf2_lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fiowv2l90VTQ",
        "colab_type": "text"
      },
      "source": [
        "It looks like using TF-IDF, we were able to improve the recall, but the accuracy and precision of the first Naive Bayes model still outperforms the other models.\n",
        "\n",
        "Overall, the first Naive Bayes model (using unigrams and counts) seems to best classify positive and negative cappuccino cup reviews."
      ]
    }
  ]
}